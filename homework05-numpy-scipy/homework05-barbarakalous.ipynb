{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Terminology\n",
    "\n",
    "Describe the following terms with your own words:\n",
    "\n",
    "***boolean array:*** is an array with boolean (True/False) values\n",
    "\n",
    "***shape:*** length in all axis (rows, collumns) \n",
    "\n",
    "***axis:*** directions along the rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "***Which ways are there to select one or more elements from a Numpy array?*** indexing \n",
    "\n",
    "***What is the difference between Numpy and Scipy?*** contains more mathematic functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Download data from entsoe-e for Lecture 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lecture 6, we need to download data from the Entso-e [transparency platform](https://transparency.entsoe.eu/): Entso-e provides (almost) real-time data on European electricity systems. We will download hourly load data (i.e. electricity demand) for all systems in Europe. First, you need to get a user account at Entsoe-e [here](https://transparency.entsoe.eu/usrm/user/createPublicUser). \n",
    "\n",
    "We are going to use the S-FTP server of Entso-e. To use S-FTP in Python, you have to install the package pysftp. You can do so here in the notebook by executing the following command (please be aware that this may take some time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\barba\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pysftp\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.8.3                |   py37hc8dfbb8_1         3.1 MB  conda-forge\n",
      "    pysftp-0.2.9               |             py_1          15 KB  conda-forge\n",
      "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  pysftp             conda-forge/noarch::pysftp-0.2.9-py_1\n",
      "  python_abi         conda-forge/win-64::python_abi-3.7-1_cp37m\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                       pkgs/main::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pysftp-0.2.9         | 15 KB     |            |   0% \n",
      "pysftp-0.2.9         | 15 KB     | ########## | 100% \n",
      "\n",
      "conda-4.8.3          | 3.1 MB    |            |   0% \n",
      "conda-4.8.3          | 3.1 MB    | 6          |   7% \n",
      "conda-4.8.3          | 3.1 MB    | ###2       |  33% \n",
      "conda-4.8.3          | 3.1 MB    | #####1     |  51% \n",
      "conda-4.8.3          | 3.1 MB    | #######    |  71% \n",
      "conda-4.8.3          | 3.1 MB    | #########  |  91% \n",
      "conda-4.8.3          | 3.1 MB    | ########## | 100% \n",
      "\n",
      "python_abi-3.7       | 4 KB      |            |   0% \n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge pysftp --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to download the data. In principle, you simply have to fill out your account information (by setting ```USER``` and ```PWD```), decide where to put the data locally by assigning a path to a ```DOWNLOAD_DIR``` and run the 4 cells below. If the download directory does not exist, it will be created. The download will take some time, so you may want to run the script overnight. \n",
    "\n",
    "If the download fails at some point, you can restart it by simply executing the cell again. Files which are already downloaded will not be downloaded again. ***Hint:*** I had problems downloading to a directoy which was on a google drive - so if you run into an error message, which says ```OSError: size mismatch in get!``` you may want to choose a directory which is not on a google drive or possibly a dropbox. Also, this error may occur if your disk is full. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysftp\n",
    "\n",
    "# if you want, you can modify this too, per default it will create a folder\n",
    "# in the parant folder of the homework repository:\n",
    "DOWNLOAD_DIR = '../entsoe-data'\n",
    "\n",
    "CATEGORIES = [\n",
    "    'ActualTotalLoad'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User for ENTSO-E API:········\n",
      "Password for ENTSO-E API:········\n"
     ]
    }
   ],
   "source": [
    "# To avoid storing the user credentials in the public Github repository,\n",
    "# these commands will ask you to enter them interactively:\n",
    "from getpass import getpass\n",
    "user = getpass('User for ENTSO-E API:')\n",
    "pwd = getpass('Password for ENTSO-E API:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_entsoe_data(user, pwd, category, output_dir, server_uri='sftp-transparency.entsoe.eu'):\n",
    "    \"\"\"Download a dataset from ENTSO-E's transparency data sftp server.\n",
    "    \n",
    "    Contact ENTSO-E to receive login credentials:\n",
    "    https://transparency.entsoe.eu/usrm/user/createPublicUser\n",
    "    \n",
    "    :param user: user name required for connecting with sftp server\n",
    "    :param pwd: password required for connecting with sftp server\n",
    "    :param category: ENTSO-E data category to be downloaded\n",
    "    :param output_dir: directory where downloaded data is saved to, a separate \n",
    "        subdirectory is created for each category.\n",
    "    :param server_uri: URI of ENTSO-E transparency server (default last updated on 2020-05-01)\n",
    "    \n",
    "    \"\"\"\n",
    "    abspath = os.path.abspath(output_dir)\n",
    "    \n",
    "    # check if local_dir exists and create if it doesn't\n",
    "    if not os.path.exists(abspath):\n",
    "        os.mkdir(abspath)\n",
    "        print (f'Successfully created the directory {abspath} and using it for download')\n",
    "    else:\n",
    "        print (f'{abspath} exists and will be used for download')  \n",
    "\n",
    "    print(\"\\nCopy this path for other notebooks, e.g. the next lecture or homework:\\n\"\n",
    "          f\"DOWNLOAD_DIR = '{abspath}'\\n\")\n",
    "        \n",
    "    cnopts = pysftp.CnOpts()\n",
    "    cnopts.hostkeys = None\n",
    "    \n",
    "    # connect to entsoe server via sFTP\n",
    "    entsoe_dir = f'/TP_export/{category}'\n",
    "   \n",
    "    with pysftp.Connection(server_uri, username=user, password=pwd, cnopts=cnopts) as sftp:\n",
    "        sftp.chdir(entsoe_dir)\n",
    "        files_entsoe = sftp.listdir()\n",
    "        to_download = list(files_entsoe)\n",
    "        \n",
    "        print(f'In total, {len(to_download)} files are going to be downloaded')\n",
    "        \n",
    "        # download files not on disk\n",
    "        \n",
    "        for file in to_download:\n",
    "            print(f'Downloading file {file}...')\n",
    "            \n",
    "            dest_file = os.path.join(abspath, file)\n",
    "            \n",
    "            if not os.path.exists(dest_file):\n",
    "                temp_file = os.path.join(abspath, f'{file}.partial')\n",
    "                \n",
    "                sftp.get(f'{entsoe_dir}/{file}', temp_file)\n",
    "                \n",
    "                os.rename(temp_file, dest_file)                   \n",
    "                print(f'{file} downloaded successfully.')\n",
    "                \n",
    "            else:\n",
    "                 print(f'{file} already present locally, skipping download.')\n",
    "           \n",
    "    sftp.close()\n",
    "    print(\"All downloads completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barba\\entso\\entsoe-data exists and will be used for download\n",
      "\n",
      "Copy this path for other notebooks, e.g. the next lecture or homework:\n",
      "DOWNLOAD_DIR = 'C:\\Users\\barba\\entso\\entsoe-data'\n",
      "\n",
      "In total, 68 files are going to be downloaded\n",
      "Downloading file 2014_12_ActualTotalLoad.csv...\n",
      "2014_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_10_ActualTotalLoad.csv...\n",
      "2015_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_11_ActualTotalLoad.csv...\n",
      "2015_11_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_12_ActualTotalLoad.csv...\n",
      "2015_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_1_ActualTotalLoad.csv...\n",
      "2015_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_2_ActualTotalLoad.csv...\n",
      "2015_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_3_ActualTotalLoad.csv...\n",
      "2015_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_4_ActualTotalLoad.csv...\n",
      "2015_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_5_ActualTotalLoad.csv...\n",
      "2015_5_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_6_ActualTotalLoad.csv...\n",
      "2015_6_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_7_ActualTotalLoad.csv...\n",
      "2015_7_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_8_ActualTotalLoad.csv...\n",
      "2015_8_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2015_9_ActualTotalLoad.csv...\n",
      "2015_9_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_10_ActualTotalLoad.csv...\n",
      "2016_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_11_ActualTotalLoad.csv...\n",
      "2016_11_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_12_ActualTotalLoad.csv...\n",
      "2016_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_1_ActualTotalLoad.csv...\n",
      "2016_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_2_ActualTotalLoad.csv...\n",
      "2016_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_3_ActualTotalLoad.csv...\n",
      "2016_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_4_ActualTotalLoad.csv...\n",
      "2016_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_5_ActualTotalLoad.csv...\n",
      "2016_5_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_6_ActualTotalLoad.csv...\n",
      "2016_6_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_7_ActualTotalLoad.csv...\n",
      "2016_7_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_8_ActualTotalLoad.csv...\n",
      "2016_8_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2016_9_ActualTotalLoad.csv...\n",
      "2016_9_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_10_ActualTotalLoad.csv...\n",
      "2017_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_11_ActualTotalLoad.csv...\n",
      "2017_11_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_12_ActualTotalLoad.csv...\n",
      "2017_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_1_ActualTotalLoad.csv...\n",
      "2017_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_2_ActualTotalLoad.csv...\n",
      "2017_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_3_ActualTotalLoad.csv...\n",
      "2017_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_4_ActualTotalLoad.csv...\n",
      "2017_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_5_ActualTotalLoad.csv...\n",
      "2017_5_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_6_ActualTotalLoad.csv...\n",
      "2017_6_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_7_ActualTotalLoad.csv...\n",
      "2017_7_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_8_ActualTotalLoad.csv...\n",
      "2017_8_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2017_9_ActualTotalLoad.csv...\n",
      "2017_9_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_10_ActualTotalLoad.csv...\n",
      "2018_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_11_ActualTotalLoad.csv...\n",
      "2018_11_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_12_ActualTotalLoad.csv...\n",
      "2018_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_1_ActualTotalLoad.csv...\n",
      "2018_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_2_ActualTotalLoad.csv...\n",
      "2018_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_3_ActualTotalLoad.csv...\n",
      "2018_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_4_ActualTotalLoad.csv...\n",
      "2018_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_5_ActualTotalLoad.csv...\n",
      "2018_5_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_6_ActualTotalLoad.csv...\n",
      "2018_6_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_7_ActualTotalLoad.csv...\n",
      "2018_7_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_8_ActualTotalLoad.csv...\n",
      "2018_8_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2018_9_ActualTotalLoad.csv...\n",
      "2018_9_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_10_ActualTotalLoad.csv...\n",
      "2019_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_11_ActualTotalLoad.csv...\n",
      "2019_11_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_12_ActualTotalLoad.csv...\n",
      "2019_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_1_ActualTotalLoad.csv...\n",
      "2019_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_2_ActualTotalLoad.csv...\n",
      "2019_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_3_ActualTotalLoad.csv...\n",
      "2019_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_4_ActualTotalLoad.csv...\n",
      "2019_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_5_ActualTotalLoad.csv...\n",
      "2019_5_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_6_ActualTotalLoad.csv...\n",
      "2019_6_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_7_ActualTotalLoad.csv...\n",
      "2019_7_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_8_ActualTotalLoad.csv...\n",
      "2019_8_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2019_9_ActualTotalLoad.csv...\n",
      "2019_9_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_10_ActualTotalLoad.csv...\n",
      "2020_10_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_12_ActualTotalLoad.csv...\n",
      "2020_12_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_1_ActualTotalLoad.csv...\n",
      "2020_1_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_2_ActualTotalLoad.csv...\n",
      "2020_2_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_3_ActualTotalLoad.csv...\n",
      "2020_3_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_4_ActualTotalLoad.csv...\n",
      "2020_4_ActualTotalLoad.csv downloaded successfully.\n",
      "Downloading file 2020_5_ActualTotalLoad.csv...\n",
      "2020_5_ActualTotalLoad.csv downloaded successfully.\n",
      "All downloads completed\n"
     ]
    }
   ],
   "source": [
    "# download data...\n",
    "for category in CATEGORIES:\n",
    "    download_entsoe_data(user, pwd, category, DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Privacy note:** If you don't want to publish the path to your repository on Github (it may contain your Windows user name for example), clear the output of the cell above before saving the Notebook! (In the menu via Cell -> Current outputs -> Clear.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Create a diagonal matrix\n",
    "\n",
    "Create a matrix `m` with shape `(4, 4)` by using `np.zeros()` and set the 4 diagonal elements to `1` by using indexing using `np.arange()`. Do not use more two assign statements in total for this exercise!\n",
    "\n",
    "Bonus: Find multiple ways to avoid calling `np.arange()` twice and analyze which is the best regarding readability, performance and memory usage!\n",
    "\n",
    "Note: Normally you would use `np.diag()` to do this. You can also have a look into the code using `np.diag??`, but it's probably easier to write your own implementation (which might be less generic and slower, but way simpler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import urllib\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "m = np.zeros((4, 4))\n",
    "print(m)\n",
    "\n",
    "# did not use np.arange()\n",
    "np.fill_diagonal(m, 1,)\n",
    "print(m)\n",
    "\n",
    "# use arange\n",
    "i = np.arange(0, -1, 4)\n",
    "m[i, i] = 1\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Invasion\n",
    "\n",
    "Create a canvas using `np.zeros()` of shape `(8, 11)`. Then set the following elements to one using fancy slicing techniques:\n",
    "\n",
    " - Rows 4 and 5 completely.\n",
    " - In row 3 all elements except the first one.\n",
    " - In row 2 all elements except the first two ones.\n",
    " - The two elements defined by: `row_idcs, column_idcs = [0, 1], [2, 3]`\n",
    " - In row 6 the elements in column 0 and 2.\n",
    " - In row 7 all elements except the first three and the last three.\n",
    " \n",
    "And then afterwards the following elements to zero:\n",
    " - The three elements defined by: `row_idcs, column_idcs = [3, 5, 7], [3, 1, 5]`\n",
    "\n",
    "As a last step, set assign the content of the first five columns to the last five columns in reversed order. This can be done by using a `step=-1` and starting with 4, i.e. the first five columns in reversed order are indexed by `canvas[:, 4::-1]`.\n",
    "\n",
    "Then plot the canvas using `plt.imshow()` with the parameter `cmap='gray'`!\n",
    "\n",
    "**Hint:** it helps a lot to have all commands in one cell (including the `imshow()` command) and execute the cell often, to check the result.\n",
    "\n",
    "**Note:** When ever the instruction says \"first element\" it is something like `x[0]`, because it refers to the first one in the array. If it is column 1 or row 1 it is `x[1]`, because it refers then to the index of the column/row.\n",
    "\n",
    "**Note:** It is `canvas[row_index, column_index]`, so if you are thinking in x/y coordinates, it is `canvas[y, x]` and the y axis goes downwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22f13590c08>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "canvas = np.zeros((8, 11))\n",
    "\n",
    "\n",
    "canvas[4:6] = 1\n",
    "canvas[3, 1:] = 1\n",
    "canvas[2, 2:] = 1\n",
    "row_idcs, column_idcs = [0, 1], [2, 3]\n",
    "canvas[row_idcs, column_idcs] = 1\n",
    "canvas[6, [0,2]] = 1\n",
    "canvas[7, 3:-3] = 1\n",
    "\n",
    "row_idcs, column_idcs = [3, 5, 7], [3, 1, 5]\n",
    "canvas[row_idcs, column_idcs] = 0\n",
    "\n",
    "canvas[:, -5:] = canvas[:, 4::-1]\n",
    "\n",
    "print(canvas)\n",
    "\n",
    "plt.imshow(canvas, cmap = 'gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Draw a circle\n",
    "\n",
    "Draw a full circle: first define a resolution e.g. $N=50$. Then define coordinates $x$ and $y$ using `np.linspace()` and pass the resolution as parameter `num=N`. Use `np.meshgrid()` to define a grid `xx` and `yy`. Define a canvas of shape `(N, N)` using `np.zeros()`. Then use the circle formula $x^2 + y^2 < r^2$ to define all circle points on the grid (use $r=2$). Then use the boolean 2D expression to set the inside of the circle to 1. Finally plot the canvas using `imshow()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6 - Frequency of shades of gray\n",
    "\n",
    "Convert the picture `numpy-meme.png` to gray scale and plot a histogram!\n",
    "\n",
    "**Instructions:** Load the image by using `plt.imread()`. This will return a three dimensional array (width, height and colors) with values between zero and one. Using the formula `gray = red * 0.2125 + green * 0.7154 + blue * 0.0721`, convert the picture to shades of gray. Look at the shape of the image and pick the right axis by looking at the length of the array in this axis! You can first calculate a weighted version of the array by multiplying with a vector of length 3 (and the three weights) and then sum along the right axis. Check the shape of the gray image afterwards and plot it using `plt.imshow()` with the parameter `cmap='gray'`. It should be only two dimensional now. Use `image_gray.flatten()` to get all pixels as one-dimensional vector and pass this to the function `plt.hist()` with the parameter `bins=50` to get 50 bins with different gray values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('figure', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 - Count colors  (optional)\n",
    "\n",
    "Calculate the number of colors used in the picture `numpy-meme.png` and the percentage of the color space (3 x 8bit, i.e. 256 values per color) used!\n",
    "\n",
    "**Instructions:** Load the image by using `plt.imread()`. This will return a three dimensional array (width, height and colors) with values between zero and one. Multiplying the array with 255 will restore the original 8bit values (integer values between 0 and 255). After multiplying by 255 use `image = image.astype(int)` to convert the image to integer type. Plot the `image` using `plt.imshow()` to see the image and guess the result. Check the shape of the array. One of the axes is of length three - this is the color axis (red, green and blue). We want to map all colors to unique integers. This can be done by defining `colors = red  + green * 256 + blue * 256**2`. This is a unique mapping between the triples `(red, green, blue)` and the integers `color` similar to decimal digits (three values between 0 and 9 e.g. `(3, 5, 1)` can be mapped to a three digit number `3 + 5 * 10 + 1 * 100 = 153`). Then use `np.unique()` to get an array with unique colors (in the mapped form as in `color`). This can be used to determine the number of unique colors in the image. This value can also be used to calculate the percentage of the color space used.\n",
    "\n",
    "<small>Image source: https://me.me/i/1-import-numpy-1-import-numpy-as-np-there-is-e4a6fb9cf75b413dbb3154794fd3d603</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by [this exercise](https://github.com/rougier/numpy-100/blob/master/100_Numpy_exercises_with_solutions.md#66-considering-a-wh3-image-of-dtypeubyte-compute-the-number-of-unique-colors-) (MIT licensed, [DOI](https://zenodo.org/badge/latestdoi/10173/rougier/numpy-100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
